{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.658374792703151,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04145936981757877,
      "grad_norm": 0.44551166892051697,
      "learning_rate": 0.0001999094977729816,
      "loss": 1.3411,
      "step": 50
    },
    {
      "epoch": 0.08291873963515754,
      "grad_norm": 0.5294526815414429,
      "learning_rate": 0.00019963073720600383,
      "loss": 1.2386,
      "step": 100
    },
    {
      "epoch": 0.12437810945273632,
      "grad_norm": 0.4422945976257324,
      "learning_rate": 0.00019916420597040514,
      "loss": 1.1964,
      "step": 150
    },
    {
      "epoch": 0.16583747927031509,
      "grad_norm": 0.5680469870567322,
      "learning_rate": 0.0001985107833217696,
      "loss": 1.1749,
      "step": 200
    },
    {
      "epoch": 0.20729684908789386,
      "grad_norm": 0.42337313294410706,
      "learning_rate": 0.00019767170074358383,
      "loss": 1.1543,
      "step": 250
    },
    {
      "epoch": 0.24875621890547264,
      "grad_norm": 0.5032064318656921,
      "learning_rate": 0.00019664853962630176,
      "loss": 1.1344,
      "step": 300
    },
    {
      "epoch": 0.2902155887230514,
      "grad_norm": 0.4354507327079773,
      "learning_rate": 0.00019544322828695169,
      "loss": 1.1216,
      "step": 350
    },
    {
      "epoch": 0.33167495854063017,
      "grad_norm": 0.5167489051818848,
      "learning_rate": 0.00019405803833490273,
      "loss": 1.1039,
      "step": 400
    },
    {
      "epoch": 0.373134328358209,
      "grad_norm": 0.4346689283847809,
      "learning_rate": 0.00019249558039063968,
      "loss": 1.0951,
      "step": 450
    },
    {
      "epoch": 0.41459369817578773,
      "grad_norm": 0.48580557107925415,
      "learning_rate": 0.00019075879916561513,
      "loss": 1.089,
      "step": 500
    },
    {
      "epoch": 0.4560530679933665,
      "grad_norm": 0.5583249926567078,
      "learning_rate": 0.0001888509679124519,
      "loss": 1.0788,
      "step": 550
    },
    {
      "epoch": 0.4975124378109453,
      "grad_norm": 0.45593032240867615,
      "learning_rate": 0.00018677568225595486,
      "loss": 1.0705,
      "step": 600
    },
    {
      "epoch": 0.538971807628524,
      "grad_norm": 0.4643898010253906,
      "learning_rate": 0.00018453685341655884,
      "loss": 1.0693,
      "step": 650
    },
    {
      "epoch": 0.5804311774461028,
      "grad_norm": 0.4817887246608734,
      "learning_rate": 0.0001821387008389843,
      "loss": 1.0613,
      "step": 700
    },
    {
      "epoch": 0.6218905472636815,
      "grad_norm": 0.4975850284099579,
      "learning_rate": 0.00017958574423999316,
      "loss": 1.0561,
      "step": 750
    },
    {
      "epoch": 0.6633499170812603,
      "grad_norm": 0.45815667510032654,
      "learning_rate": 0.00017688279509023183,
      "loss": 1.0522,
      "step": 800
    },
    {
      "epoch": 0.7048092868988391,
      "grad_norm": 0.4514096975326538,
      "learning_rate": 0.000174034947546216,
      "loss": 1.0512,
      "step": 850
    },
    {
      "epoch": 0.746268656716418,
      "grad_norm": 0.44456756114959717,
      "learning_rate": 0.00017104756884954667,
      "loss": 1.0482,
      "step": 900
    },
    {
      "epoch": 0.7877280265339967,
      "grad_norm": 0.4492434561252594,
      "learning_rate": 0.00016792628921145211,
      "loss": 1.0462,
      "step": 950
    },
    {
      "epoch": 0.8291873963515755,
      "grad_norm": 0.46116024255752563,
      "learning_rate": 0.00016467699120171987,
      "loss": 1.0369,
      "step": 1000
    },
    {
      "epoch": 0.8706467661691543,
      "grad_norm": 0.48085394501686096,
      "learning_rate": 0.00016130579866201715,
      "loss": 1.0369,
      "step": 1050
    },
    {
      "epoch": 0.912106135986733,
      "grad_norm": 0.45279672741889954,
      "learning_rate": 0.00015781906516449429,
      "loss": 1.0272,
      "step": 1100
    },
    {
      "epoch": 0.9535655058043118,
      "grad_norm": 0.4344383776187897,
      "learning_rate": 0.00015422336203742293,
      "loss": 1.0317,
      "step": 1150
    },
    {
      "epoch": 0.9950248756218906,
      "grad_norm": 0.5133271813392639,
      "learning_rate": 0.0001505254659804369,
      "loss": 1.0202,
      "step": 1200
    },
    {
      "epoch": 1.0364842454394694,
      "grad_norm": 0.45206576585769653,
      "learning_rate": 0.00014673234629271616,
      "loss": 0.9924,
      "step": 1250
    },
    {
      "epoch": 1.077943615257048,
      "grad_norm": 0.4813695549964905,
      "learning_rate": 0.00014285115173818532,
      "loss": 0.9824,
      "step": 1300
    },
    {
      "epoch": 1.1194029850746268,
      "grad_norm": 0.45866599678993225,
      "learning_rate": 0.00013888919707248095,
      "loss": 0.9872,
      "step": 1350
    },
    {
      "epoch": 1.1608623548922057,
      "grad_norm": 0.45224446058273315,
      "learning_rate": 0.00013485394925707986,
      "loss": 0.9986,
      "step": 1400
    },
    {
      "epoch": 1.2023217247097844,
      "grad_norm": 0.4541942775249481,
      "learning_rate": 0.00013075301338657036,
      "loss": 0.9859,
      "step": 1450
    },
    {
      "epoch": 1.243781094527363,
      "grad_norm": 0.438620924949646,
      "learning_rate": 0.00012659411835558843,
      "loss": 0.9705,
      "step": 1500
    },
    {
      "epoch": 1.285240464344942,
      "grad_norm": 0.4662292003631592,
      "learning_rate": 0.0001223851022924326,
      "loss": 0.989,
      "step": 1550
    },
    {
      "epoch": 1.3266998341625207,
      "grad_norm": 0.4597610533237457,
      "learning_rate": 0.00011813389778680939,
      "loss": 0.9876,
      "step": 1600
    },
    {
      "epoch": 1.3681592039800994,
      "grad_norm": 0.44800665974617004,
      "learning_rate": 0.00011384851693955082,
      "loss": 0.9888,
      "step": 1650
    },
    {
      "epoch": 1.4096185737976783,
      "grad_norm": 0.4384419918060303,
      "learning_rate": 0.00010953703626247995,
      "loss": 0.9819,
      "step": 1700
    },
    {
      "epoch": 1.451077943615257,
      "grad_norm": 0.44551321864128113,
      "learning_rate": 0.00010520758145688325,
      "loss": 0.9814,
      "step": 1750
    },
    {
      "epoch": 1.4925373134328357,
      "grad_norm": 0.45181265473365784,
      "learning_rate": 0.00010086831209927699,
      "loss": 0.979,
      "step": 1800
    },
    {
      "epoch": 1.5339966832504146,
      "grad_norm": 0.44708868861198425,
      "learning_rate": 9.652740626333057e-05,
      "loss": 0.9786,
      "step": 1850
    },
    {
      "epoch": 1.5754560530679935,
      "grad_norm": 0.42666372656822205,
      "learning_rate": 9.219304510692852e-05,
      "loss": 0.9737,
      "step": 1900
    },
    {
      "epoch": 1.616915422885572,
      "grad_norm": 0.4454438388347626,
      "learning_rate": 8.787339745341998e-05,
      "loss": 0.9725,
      "step": 1950
    },
    {
      "epoch": 1.658374792703151,
      "grad_norm": 0.45314204692840576,
      "learning_rate": 8.357660439611473e-05,
      "loss": 0.9815,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3618,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.903914360759386e+18,
  "train_batch_size": 112,
  "trial_name": null,
  "trial_params": null
}
