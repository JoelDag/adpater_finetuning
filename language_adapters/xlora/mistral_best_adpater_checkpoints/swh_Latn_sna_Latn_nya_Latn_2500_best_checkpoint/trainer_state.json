{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7082152974504249,
  "eval_steps": 501,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0056657223796034,
      "grad_norm": 0.7914698123931885,
      "learning_rate": 0.00019999841151220753,
      "loss": 2.7102,
      "step": 20
    },
    {
      "epoch": 0.0113314447592068,
      "grad_norm": 0.8829830884933472,
      "learning_rate": 0.00019999330728704055,
      "loss": 2.4643,
      "step": 40
    },
    {
      "epoch": 0.0169971671388102,
      "grad_norm": 0.9751067757606506,
      "learning_rate": 0.00019998468310392288,
      "loss": 2.3242,
      "step": 60
    },
    {
      "epoch": 0.0226628895184136,
      "grad_norm": 1.021403431892395,
      "learning_rate": 0.00019997253926644248,
      "loss": 2.2611,
      "step": 80
    },
    {
      "epoch": 0.028328611898016998,
      "grad_norm": 1.0026862621307373,
      "learning_rate": 0.0001999568762020859,
      "loss": 2.1998,
      "step": 100
    },
    {
      "epoch": 0.0339943342776204,
      "grad_norm": 1.009087324142456,
      "learning_rate": 0.00019993769446222332,
      "loss": 2.1539,
      "step": 120
    },
    {
      "epoch": 0.039660056657223795,
      "grad_norm": 0.9915069937705994,
      "learning_rate": 0.00019991499472208913,
      "loss": 2.0784,
      "step": 140
    },
    {
      "epoch": 0.0453257790368272,
      "grad_norm": 0.9519336819648743,
      "learning_rate": 0.00019988877778075807,
      "loss": 2.0669,
      "step": 160
    },
    {
      "epoch": 0.05099150141643059,
      "grad_norm": 0.9963748455047607,
      "learning_rate": 0.00019985904456111726,
      "loss": 2.0279,
      "step": 180
    },
    {
      "epoch": 0.056657223796033995,
      "grad_norm": 0.927021861076355,
      "learning_rate": 0.00019982579610983362,
      "loss": 2.0178,
      "step": 200
    },
    {
      "epoch": 0.06232294617563739,
      "grad_norm": 0.9282698035240173,
      "learning_rate": 0.0001997890335973169,
      "loss": 1.9841,
      "step": 220
    },
    {
      "epoch": 0.0679886685552408,
      "grad_norm": 0.9189260601997375,
      "learning_rate": 0.00019974875831767872,
      "loss": 1.9899,
      "step": 240
    },
    {
      "epoch": 0.07365439093484419,
      "grad_norm": 0.9249326586723328,
      "learning_rate": 0.0001997049716886869,
      "loss": 1.964,
      "step": 260
    },
    {
      "epoch": 0.07932011331444759,
      "grad_norm": 0.925095796585083,
      "learning_rate": 0.00019965767525171552,
      "loss": 1.9355,
      "step": 280
    },
    {
      "epoch": 0.08498583569405099,
      "grad_norm": 0.9269723296165466,
      "learning_rate": 0.0001996068706716907,
      "loss": 1.9267,
      "step": 300
    },
    {
      "epoch": 0.0906515580736544,
      "grad_norm": 0.9312129616737366,
      "learning_rate": 0.00019955255973703198,
      "loss": 1.9361,
      "step": 320
    },
    {
      "epoch": 0.09631728045325778,
      "grad_norm": 0.9081538915634155,
      "learning_rate": 0.00019949474435958936,
      "loss": 1.897,
      "step": 340
    },
    {
      "epoch": 0.10198300283286119,
      "grad_norm": 0.8693727850914001,
      "learning_rate": 0.0001994334265745761,
      "loss": 1.8946,
      "step": 360
    },
    {
      "epoch": 0.10764872521246459,
      "grad_norm": 0.8906344175338745,
      "learning_rate": 0.0001993686085404968,
      "loss": 1.8784,
      "step": 380
    },
    {
      "epoch": 0.11331444759206799,
      "grad_norm": 0.9008004069328308,
      "learning_rate": 0.00019930029253907182,
      "loss": 1.8588,
      "step": 400
    },
    {
      "epoch": 0.11898016997167139,
      "grad_norm": 0.828893780708313,
      "learning_rate": 0.00019922848097515656,
      "loss": 1.8587,
      "step": 420
    },
    {
      "epoch": 0.12464589235127478,
      "grad_norm": 0.8637949228286743,
      "learning_rate": 0.0001991531763766571,
      "loss": 1.8569,
      "step": 440
    },
    {
      "epoch": 0.13031161473087818,
      "grad_norm": 0.8574060797691345,
      "learning_rate": 0.00019907438139444102,
      "loss": 1.8436,
      "step": 460
    },
    {
      "epoch": 0.1359773371104816,
      "grad_norm": 0.8573303818702698,
      "learning_rate": 0.00019899209880224424,
      "loss": 1.8368,
      "step": 480
    },
    {
      "epoch": 0.141643059490085,
      "grad_norm": 0.8338489532470703,
      "learning_rate": 0.00019890633149657324,
      "loss": 1.8373,
      "step": 500
    },
    {
      "epoch": 0.14192634560906517,
      "eval_loss": 1.9474380016326904,
      "eval_runtime": 0.5378,
      "eval_samples_per_second": 18.595,
      "eval_steps_per_second": 3.719,
      "step": 501
    },
    {
      "epoch": 0.14730878186968838,
      "grad_norm": 0.8346986174583435,
      "learning_rate": 0.00019881708249660317,
      "loss": 1.8128,
      "step": 520
    },
    {
      "epoch": 0.1529745042492918,
      "grad_norm": 0.8192846775054932,
      "learning_rate": 0.0001987243549440716,
      "loss": 1.8208,
      "step": 540
    },
    {
      "epoch": 0.15864022662889518,
      "grad_norm": 0.8728092312812805,
      "learning_rate": 0.00019862815210316783,
      "loss": 1.8086,
      "step": 560
    },
    {
      "epoch": 0.1643059490084986,
      "grad_norm": 0.8880193829536438,
      "learning_rate": 0.00019852847736041805,
      "loss": 1.8078,
      "step": 580
    },
    {
      "epoch": 0.16997167138810199,
      "grad_norm": 0.8494848012924194,
      "learning_rate": 0.00019842533422456614,
      "loss": 1.7969,
      "step": 600
    },
    {
      "epoch": 0.17563739376770537,
      "grad_norm": 0.8131103515625,
      "learning_rate": 0.0001983187263264501,
      "loss": 1.7968,
      "step": 620
    },
    {
      "epoch": 0.1813031161473088,
      "grad_norm": 0.8138723373413086,
      "learning_rate": 0.00019820865741887426,
      "loss": 1.7828,
      "step": 640
    },
    {
      "epoch": 0.18696883852691218,
      "grad_norm": 0.8118337392807007,
      "learning_rate": 0.00019809513137647726,
      "loss": 1.7806,
      "step": 660
    },
    {
      "epoch": 0.19263456090651557,
      "grad_norm": 0.8144243359565735,
      "learning_rate": 0.00019797815219559545,
      "loss": 1.7771,
      "step": 680
    },
    {
      "epoch": 0.19830028328611898,
      "grad_norm": 0.8320033550262451,
      "learning_rate": 0.00019785772399412248,
      "loss": 1.7867,
      "step": 700
    },
    {
      "epoch": 0.20396600566572237,
      "grad_norm": 0.8417283892631531,
      "learning_rate": 0.00019773385101136407,
      "loss": 1.7786,
      "step": 720
    },
    {
      "epoch": 0.2096317280453258,
      "grad_norm": 0.8234197497367859,
      "learning_rate": 0.00019760653760788897,
      "loss": 1.7745,
      "step": 740
    },
    {
      "epoch": 0.21529745042492918,
      "grad_norm": 0.8266847133636475,
      "learning_rate": 0.0001974757882653754,
      "loss": 1.7608,
      "step": 760
    },
    {
      "epoch": 0.22096317280453256,
      "grad_norm": 0.7877482175827026,
      "learning_rate": 0.00019734160758645334,
      "loss": 1.7439,
      "step": 780
    },
    {
      "epoch": 0.22662889518413598,
      "grad_norm": 0.8064917922019958,
      "learning_rate": 0.00019720400029454228,
      "loss": 1.7517,
      "step": 800
    },
    {
      "epoch": 0.23229461756373937,
      "grad_norm": 0.8585337400436401,
      "learning_rate": 0.00019706297123368535,
      "loss": 1.7652,
      "step": 820
    },
    {
      "epoch": 0.23796033994334279,
      "grad_norm": 0.8216091990470886,
      "learning_rate": 0.00019691852536837833,
      "loss": 1.7328,
      "step": 840
    },
    {
      "epoch": 0.24362606232294617,
      "grad_norm": 0.829532265663147,
      "learning_rate": 0.00019677066778339531,
      "loss": 1.7499,
      "step": 860
    },
    {
      "epoch": 0.24929178470254956,
      "grad_norm": 0.7948644161224365,
      "learning_rate": 0.00019661940368360947,
      "loss": 1.7477,
      "step": 880
    },
    {
      "epoch": 0.254957507082153,
      "grad_norm": 0.7778187394142151,
      "learning_rate": 0.0001964647383938099,
      "loss": 1.7496,
      "step": 900
    },
    {
      "epoch": 0.26062322946175637,
      "grad_norm": 0.7968010306358337,
      "learning_rate": 0.00019630667735851407,
      "loss": 1.7274,
      "step": 920
    },
    {
      "epoch": 0.26628895184135976,
      "grad_norm": 0.790185809135437,
      "learning_rate": 0.00019614522614177642,
      "loss": 1.7428,
      "step": 940
    },
    {
      "epoch": 0.2719546742209632,
      "grad_norm": 0.797927975654602,
      "learning_rate": 0.00019598039042699225,
      "loss": 1.7213,
      "step": 960
    },
    {
      "epoch": 0.2776203966005666,
      "grad_norm": 0.7615525126457214,
      "learning_rate": 0.00019581217601669773,
      "loss": 1.7274,
      "step": 980
    },
    {
      "epoch": 0.28328611898017,
      "grad_norm": 0.7607869505882263,
      "learning_rate": 0.00019564058883236572,
      "loss": 1.7222,
      "step": 1000
    },
    {
      "epoch": 0.28385269121813034,
      "eval_loss": 1.8729455471038818,
      "eval_runtime": 0.5334,
      "eval_samples_per_second": 18.748,
      "eval_steps_per_second": 3.75,
      "step": 1002
    },
    {
      "epoch": 0.28895184135977336,
      "grad_norm": 0.7609853148460388,
      "learning_rate": 0.00019546563491419714,
      "loss": 1.7213,
      "step": 1020
    },
    {
      "epoch": 0.29461756373937675,
      "grad_norm": 0.8074331283569336,
      "learning_rate": 0.0001952873204209086,
      "loss": 1.7088,
      "step": 1040
    },
    {
      "epoch": 0.3002832861189802,
      "grad_norm": 0.7995853424072266,
      "learning_rate": 0.00019510565162951537,
      "loss": 1.723,
      "step": 1060
    },
    {
      "epoch": 0.3059490084985836,
      "grad_norm": 0.7524343132972717,
      "learning_rate": 0.00019492063493511047,
      "loss": 1.7078,
      "step": 1080
    },
    {
      "epoch": 0.311614730878187,
      "grad_norm": 0.7517711520195007,
      "learning_rate": 0.00019473227685063972,
      "loss": 1.72,
      "step": 1100
    },
    {
      "epoch": 0.31728045325779036,
      "grad_norm": 0.7564552426338196,
      "learning_rate": 0.00019454058400667222,
      "loss": 1.7001,
      "step": 1120
    },
    {
      "epoch": 0.32294617563739375,
      "grad_norm": 0.76985764503479,
      "learning_rate": 0.00019434556315116707,
      "loss": 1.7174,
      "step": 1140
    },
    {
      "epoch": 0.3286118980169972,
      "grad_norm": 0.7591193318367004,
      "learning_rate": 0.00019414722114923584,
      "loss": 1.6955,
      "step": 1160
    },
    {
      "epoch": 0.3342776203966006,
      "grad_norm": 0.7667289972305298,
      "learning_rate": 0.0001939455649829009,
      "loss": 1.7042,
      "step": 1180
    },
    {
      "epoch": 0.33994334277620397,
      "grad_norm": 0.7463240623474121,
      "learning_rate": 0.00019374060175084961,
      "loss": 1.7011,
      "step": 1200
    },
    {
      "epoch": 0.34560906515580736,
      "grad_norm": 0.7933082580566406,
      "learning_rate": 0.00019353233866818446,
      "loss": 1.7009,
      "step": 1220
    },
    {
      "epoch": 0.35127478753541075,
      "grad_norm": 0.787471354007721,
      "learning_rate": 0.000193320783066169,
      "loss": 1.7023,
      "step": 1240
    },
    {
      "epoch": 0.35694050991501414,
      "grad_norm": 0.7727733254432678,
      "learning_rate": 0.0001931059423919699,
      "loss": 1.7042,
      "step": 1260
    },
    {
      "epoch": 0.3626062322946176,
      "grad_norm": 0.7685943841934204,
      "learning_rate": 0.00019288782420839474,
      "loss": 1.6945,
      "step": 1280
    },
    {
      "epoch": 0.36827195467422097,
      "grad_norm": 0.748009443283081,
      "learning_rate": 0.00019266643619362568,
      "loss": 1.698,
      "step": 1300
    },
    {
      "epoch": 0.37393767705382436,
      "grad_norm": 0.7483175992965698,
      "learning_rate": 0.00019244178614094936,
      "loss": 1.6841,
      "step": 1320
    },
    {
      "epoch": 0.37960339943342775,
      "grad_norm": 0.7611216306686401,
      "learning_rate": 0.00019221388195848248,
      "loss": 1.7068,
      "step": 1340
    },
    {
      "epoch": 0.38526912181303113,
      "grad_norm": 0.7728532552719116,
      "learning_rate": 0.00019198273166889333,
      "loss": 1.6852,
      "step": 1360
    },
    {
      "epoch": 0.3909348441926346,
      "grad_norm": 0.7661702632904053,
      "learning_rate": 0.00019174834340911944,
      "loss": 1.6748,
      "step": 1380
    },
    {
      "epoch": 0.39660056657223797,
      "grad_norm": 0.7296989560127258,
      "learning_rate": 0.00019151072543008128,
      "loss": 1.6812,
      "step": 1400
    },
    {
      "epoch": 0.40226628895184136,
      "grad_norm": 0.7478007674217224,
      "learning_rate": 0.0001912698860963916,
      "loss": 1.69,
      "step": 1420
    },
    {
      "epoch": 0.40793201133144474,
      "grad_norm": 0.7571684718132019,
      "learning_rate": 0.00019102583388606103,
      "loss": 1.6612,
      "step": 1440
    },
    {
      "epoch": 0.41359773371104813,
      "grad_norm": 0.7309184074401855,
      "learning_rate": 0.0001907785773901998,
      "loss": 1.6806,
      "step": 1460
    },
    {
      "epoch": 0.4192634560906516,
      "grad_norm": 0.7125510573387146,
      "learning_rate": 0.0001905281253127151,
      "loss": 1.6594,
      "step": 1480
    },
    {
      "epoch": 0.42492917847025496,
      "grad_norm": 0.7204398512840271,
      "learning_rate": 0.00019027448647000478,
      "loss": 1.6754,
      "step": 1500
    },
    {
      "epoch": 0.4257790368271955,
      "eval_loss": 1.8164650201797485,
      "eval_runtime": 0.525,
      "eval_samples_per_second": 19.048,
      "eval_steps_per_second": 3.81,
      "step": 1503
    },
    {
      "epoch": 0.43059490084985835,
      "grad_norm": 0.7201263904571533,
      "learning_rate": 0.00019001766979064702,
      "loss": 1.6708,
      "step": 1520
    },
    {
      "epoch": 0.43626062322946174,
      "grad_norm": 0.7327618598937988,
      "learning_rate": 0.000189757684315086,
      "loss": 1.6695,
      "step": 1540
    },
    {
      "epoch": 0.44192634560906513,
      "grad_norm": 0.7418878078460693,
      "learning_rate": 0.00018949453919531365,
      "loss": 1.6592,
      "step": 1560
    },
    {
      "epoch": 0.4475920679886686,
      "grad_norm": 0.7614890336990356,
      "learning_rate": 0.00018922824369454753,
      "loss": 1.663,
      "step": 1580
    },
    {
      "epoch": 0.45325779036827196,
      "grad_norm": 0.7219182252883911,
      "learning_rate": 0.00018895880718690464,
      "loss": 1.6701,
      "step": 1600
    },
    {
      "epoch": 0.45892351274787535,
      "grad_norm": 0.7097798585891724,
      "learning_rate": 0.00018868623915707154,
      "loss": 1.6598,
      "step": 1620
    },
    {
      "epoch": 0.46458923512747874,
      "grad_norm": 0.7397447824478149,
      "learning_rate": 0.0001884105491999704,
      "loss": 1.6627,
      "step": 1640
    },
    {
      "epoch": 0.4702549575070821,
      "grad_norm": 0.7480753660202026,
      "learning_rate": 0.00018813174702042137,
      "loss": 1.6476,
      "step": 1660
    },
    {
      "epoch": 0.47592067988668557,
      "grad_norm": 0.7628557682037354,
      "learning_rate": 0.00018784984243280073,
      "loss": 1.6598,
      "step": 1680
    },
    {
      "epoch": 0.48158640226628896,
      "grad_norm": 0.7245035767555237,
      "learning_rate": 0.0001875648453606956,
      "loss": 1.6568,
      "step": 1700
    },
    {
      "epoch": 0.48725212464589235,
      "grad_norm": 0.7666491270065308,
      "learning_rate": 0.0001872767658365545,
      "loss": 1.6666,
      "step": 1720
    },
    {
      "epoch": 0.49291784702549574,
      "grad_norm": 0.7237375974655151,
      "learning_rate": 0.00018698561400133429,
      "loss": 1.6476,
      "step": 1740
    },
    {
      "epoch": 0.4985835694050991,
      "grad_norm": 0.7311282157897949,
      "learning_rate": 0.00018669140010414305,
      "loss": 1.6609,
      "step": 1760
    },
    {
      "epoch": 0.5042492917847026,
      "grad_norm": 0.7415260076522827,
      "learning_rate": 0.0001863941345018794,
      "loss": 1.6503,
      "step": 1780
    },
    {
      "epoch": 0.509915014164306,
      "grad_norm": 0.7499258518218994,
      "learning_rate": 0.00018609382765886792,
      "loss": 1.6467,
      "step": 1800
    },
    {
      "epoch": 0.5155807365439093,
      "grad_norm": 0.683401346206665,
      "learning_rate": 0.00018579049014649072,
      "loss": 1.6529,
      "step": 1820
    },
    {
      "epoch": 0.5212464589235127,
      "grad_norm": 0.6871382594108582,
      "learning_rate": 0.0001854841326428153,
      "loss": 1.6638,
      "step": 1840
    },
    {
      "epoch": 0.5269121813031161,
      "grad_norm": 0.7546985149383545,
      "learning_rate": 0.00018517476593221877,
      "loss": 1.6524,
      "step": 1860
    },
    {
      "epoch": 0.5325779036827195,
      "grad_norm": 0.6984640955924988,
      "learning_rate": 0.00018486240090500808,
      "loss": 1.6665,
      "step": 1880
    },
    {
      "epoch": 0.5382436260623229,
      "grad_norm": 0.6982248425483704,
      "learning_rate": 0.00018454704855703683,
      "loss": 1.6296,
      "step": 1900
    },
    {
      "epoch": 0.5439093484419264,
      "grad_norm": 0.7062944173812866,
      "learning_rate": 0.00018422871998931793,
      "loss": 1.6518,
      "step": 1920
    },
    {
      "epoch": 0.5495750708215298,
      "grad_norm": 0.7259661555290222,
      "learning_rate": 0.00018390742640763313,
      "loss": 1.6361,
      "step": 1940
    },
    {
      "epoch": 0.5552407932011332,
      "grad_norm": 0.700728714466095,
      "learning_rate": 0.0001835831791221384,
      "loss": 1.6477,
      "step": 1960
    },
    {
      "epoch": 0.5609065155807366,
      "grad_norm": 0.7322705388069153,
      "learning_rate": 0.00018325598954696567,
      "loss": 1.6368,
      "step": 1980
    },
    {
      "epoch": 0.56657223796034,
      "grad_norm": 0.72933030128479,
      "learning_rate": 0.0001829258691998213,
      "loss": 1.6423,
      "step": 2000
    },
    {
      "epoch": 0.5677053824362607,
      "eval_loss": 1.7758375406265259,
      "eval_runtime": 0.5401,
      "eval_samples_per_second": 18.514,
      "eval_steps_per_second": 3.703,
      "step": 2004
    },
    {
      "epoch": 0.5722379603399433,
      "grad_norm": 0.7351134419441223,
      "learning_rate": 0.00018259282970158045,
      "loss": 1.6488,
      "step": 2020
    },
    {
      "epoch": 0.5779036827195467,
      "grad_norm": 0.7273707389831543,
      "learning_rate": 0.00018225688277587806,
      "loss": 1.6373,
      "step": 2040
    },
    {
      "epoch": 0.5835694050991501,
      "grad_norm": 0.7120916247367859,
      "learning_rate": 0.0001819180402486961,
      "loss": 1.6388,
      "step": 2060
    },
    {
      "epoch": 0.5892351274787535,
      "grad_norm": 0.7008810639381409,
      "learning_rate": 0.00018157631404794734,
      "loss": 1.6508,
      "step": 2080
    },
    {
      "epoch": 0.5949008498583569,
      "grad_norm": 0.7083207368850708,
      "learning_rate": 0.0001812317162030555,
      "loss": 1.6408,
      "step": 2100
    },
    {
      "epoch": 0.6005665722379604,
      "grad_norm": 0.7055232524871826,
      "learning_rate": 0.00018088425884453164,
      "loss": 1.6426,
      "step": 2120
    },
    {
      "epoch": 0.6062322946175638,
      "grad_norm": 0.7203569412231445,
      "learning_rate": 0.00018053395420354726,
      "loss": 1.6319,
      "step": 2140
    },
    {
      "epoch": 0.6118980169971672,
      "grad_norm": 0.6995881199836731,
      "learning_rate": 0.00018018081461150377,
      "loss": 1.6427,
      "step": 2160
    },
    {
      "epoch": 0.6175637393767706,
      "grad_norm": 0.6730979084968567,
      "learning_rate": 0.00017982485249959826,
      "loss": 1.6284,
      "step": 2180
    },
    {
      "epoch": 0.623229461756374,
      "grad_norm": 0.7184272408485413,
      "learning_rate": 0.00017946608039838606,
      "loss": 1.6343,
      "step": 2200
    },
    {
      "epoch": 0.6288951841359773,
      "grad_norm": 0.7005183696746826,
      "learning_rate": 0.0001791045109373395,
      "loss": 1.644,
      "step": 2220
    },
    {
      "epoch": 0.6345609065155807,
      "grad_norm": 0.7250664830207825,
      "learning_rate": 0.00017874015684440345,
      "loss": 1.6365,
      "step": 2240
    },
    {
      "epoch": 0.6402266288951841,
      "grad_norm": 0.7146359086036682,
      "learning_rate": 0.00017837303094554713,
      "loss": 1.6464,
      "step": 2260
    },
    {
      "epoch": 0.6458923512747875,
      "grad_norm": 0.6877081990242004,
      "learning_rate": 0.00017800314616431276,
      "loss": 1.6261,
      "step": 2280
    },
    {
      "epoch": 0.6515580736543909,
      "grad_norm": 0.7160471677780151,
      "learning_rate": 0.00017763051552136056,
      "loss": 1.6277,
      "step": 2300
    },
    {
      "epoch": 0.6572237960339944,
      "grad_norm": 0.7397223114967346,
      "learning_rate": 0.00017725515213401036,
      "loss": 1.6335,
      "step": 2320
    },
    {
      "epoch": 0.6628895184135978,
      "grad_norm": 0.6922158002853394,
      "learning_rate": 0.0001768770692157799,
      "loss": 1.6332,
      "step": 2340
    },
    {
      "epoch": 0.6685552407932012,
      "grad_norm": 0.7022196054458618,
      "learning_rate": 0.00017649628007591968,
      "loss": 1.614,
      "step": 2360
    },
    {
      "epoch": 0.6742209631728046,
      "grad_norm": 0.6972169876098633,
      "learning_rate": 0.0001761127981189444,
      "loss": 1.6297,
      "step": 2380
    },
    {
      "epoch": 0.6798866855524079,
      "grad_norm": 0.6846784949302673,
      "learning_rate": 0.00017572663684416125,
      "loss": 1.6122,
      "step": 2400
    },
    {
      "epoch": 0.6855524079320113,
      "grad_norm": 0.6739820241928101,
      "learning_rate": 0.00017533780984519437,
      "loss": 1.6204,
      "step": 2420
    },
    {
      "epoch": 0.6912181303116147,
      "grad_norm": 0.6994904279708862,
      "learning_rate": 0.0001749463308095068,
      "loss": 1.6283,
      "step": 2440
    },
    {
      "epoch": 0.6968838526912181,
      "grad_norm": 0.6799800395965576,
      "learning_rate": 0.00017455221351791824,
      "loss": 1.619,
      "step": 2460
    },
    {
      "epoch": 0.7025495750708215,
      "grad_norm": 0.7132349014282227,
      "learning_rate": 0.00017415547184412017,
      "loss": 1.6276,
      "step": 2480
    },
    {
      "epoch": 0.7082152974504249,
      "grad_norm": 0.7040131688117981,
      "learning_rate": 0.0001737561197541874,
      "loss": 1.6317,
      "step": 2500
    }
  ],
  "logging_steps": 20,
  "max_steps": 10590,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.5975450157056e+18,
  "train_batch_size": 84,
  "trial_name": null,
  "trial_params": null
}
