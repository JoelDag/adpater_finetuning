{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.09369957141121965,
  "eval_steps": 500,
  "global_step": 3600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005205531745067759,
      "grad_norm": 0.4566799998283386,
      "learning_rate": 0.00019999986627428667,
      "loss": 4.3689,
      "step": 20
    },
    {
      "epoch": 0.0010411063490135518,
      "grad_norm": 0.3714560568332672,
      "learning_rate": 0.00019999946509750437,
      "loss": 4.0911,
      "step": 40
    },
    {
      "epoch": 0.0015616595235203275,
      "grad_norm": 0.3531384766101837,
      "learning_rate": 0.000199998796470726,
      "loss": 3.9444,
      "step": 60
    },
    {
      "epoch": 0.0020822126980271035,
      "grad_norm": 0.29226425290107727,
      "learning_rate": 0.0001999978603957398,
      "loss": 3.9455,
      "step": 80
    },
    {
      "epoch": 0.0026027658725338793,
      "grad_norm": 0.4175419807434082,
      "learning_rate": 0.0001999966568750494,
      "loss": 3.8862,
      "step": 100
    },
    {
      "epoch": 0.003123319047040655,
      "grad_norm": 0.3562856614589691,
      "learning_rate": 0.00019999518591187355,
      "loss": 3.8856,
      "step": 120
    },
    {
      "epoch": 0.0036438722215474313,
      "grad_norm": 0.4635142982006073,
      "learning_rate": 0.0001999934475101464,
      "loss": 3.898,
      "step": 140
    },
    {
      "epoch": 0.004164425396054207,
      "grad_norm": 0.34929248690605164,
      "learning_rate": 0.00019999144167451736,
      "loss": 3.8564,
      "step": 160
    },
    {
      "epoch": 0.004684978570560982,
      "grad_norm": 0.47370225191116333,
      "learning_rate": 0.000199989168410351,
      "loss": 3.8438,
      "step": 180
    },
    {
      "epoch": 0.005205531745067759,
      "grad_norm": 0.39079129695892334,
      "learning_rate": 0.00019998662772372722,
      "loss": 3.8173,
      "step": 200
    },
    {
      "epoch": 0.005726084919574535,
      "grad_norm": 0.4435073733329773,
      "learning_rate": 0.00019998381962144118,
      "loss": 3.8261,
      "step": 220
    },
    {
      "epoch": 0.00624663809408131,
      "grad_norm": 0.4666978120803833,
      "learning_rate": 0.0001999807441110031,
      "loss": 3.802,
      "step": 240
    },
    {
      "epoch": 0.006767191268588086,
      "grad_norm": 0.49232667684555054,
      "learning_rate": 0.00019997740120063852,
      "loss": 3.8515,
      "step": 260
    },
    {
      "epoch": 0.0072877444430948625,
      "grad_norm": 0.4043222963809967,
      "learning_rate": 0.0001999737908992881,
      "loss": 3.8447,
      "step": 280
    },
    {
      "epoch": 0.007808297617601638,
      "grad_norm": 0.42750486731529236,
      "learning_rate": 0.00019996991321660765,
      "loss": 3.7921,
      "step": 300
    },
    {
      "epoch": 0.008328850792108414,
      "grad_norm": 0.43882665038108826,
      "learning_rate": 0.00019996576816296808,
      "loss": 3.7665,
      "step": 320
    },
    {
      "epoch": 0.00884940396661519,
      "grad_norm": 0.4385984241962433,
      "learning_rate": 0.00019996135574945544,
      "loss": 3.7783,
      "step": 340
    },
    {
      "epoch": 0.009369957141121965,
      "grad_norm": 0.4346665143966675,
      "learning_rate": 0.00019995667598787065,
      "loss": 3.789,
      "step": 360
    },
    {
      "epoch": 0.009890510315628742,
      "grad_norm": 0.46042922139167786,
      "learning_rate": 0.00019995172889072997,
      "loss": 3.7081,
      "step": 380
    },
    {
      "epoch": 0.010411063490135517,
      "grad_norm": 0.4739595651626587,
      "learning_rate": 0.0001999465144712644,
      "loss": 3.7496,
      "step": 400
    },
    {
      "epoch": 0.010931616664642292,
      "grad_norm": 0.45992934703826904,
      "learning_rate": 0.00019994103274341996,
      "loss": 3.7371,
      "step": 420
    },
    {
      "epoch": 0.01145216983914907,
      "grad_norm": 0.49061375856399536,
      "learning_rate": 0.00019993528372185766,
      "loss": 3.7451,
      "step": 440
    },
    {
      "epoch": 0.011972723013655845,
      "grad_norm": 0.4901637136936188,
      "learning_rate": 0.0001999292674219533,
      "loss": 3.7169,
      "step": 460
    },
    {
      "epoch": 0.01249327618816262,
      "grad_norm": 0.4778408110141754,
      "learning_rate": 0.0001999229838597976,
      "loss": 3.6742,
      "step": 480
    },
    {
      "epoch": 0.013013829362669397,
      "grad_norm": 0.4031224250793457,
      "learning_rate": 0.000199916433052196,
      "loss": 3.7586,
      "step": 500
    },
    {
      "epoch": 0.013534382537176173,
      "grad_norm": 0.40983089804649353,
      "learning_rate": 0.00019990961501666874,
      "loss": 3.7396,
      "step": 520
    },
    {
      "epoch": 0.014054935711682948,
      "grad_norm": 0.4553685486316681,
      "learning_rate": 0.00019990252977145073,
      "loss": 3.7341,
      "step": 540
    },
    {
      "epoch": 0.014575488886189725,
      "grad_norm": 0.5718130469322205,
      "learning_rate": 0.00019989517733549162,
      "loss": 3.7074,
      "step": 560
    },
    {
      "epoch": 0.0150960420606965,
      "grad_norm": 0.4579938054084778,
      "learning_rate": 0.0001998875577284556,
      "loss": 3.7017,
      "step": 580
    },
    {
      "epoch": 0.015616595235203276,
      "grad_norm": 0.5239989757537842,
      "learning_rate": 0.00019987967097072134,
      "loss": 3.7612,
      "step": 600
    },
    {
      "epoch": 0.01613714840971005,
      "grad_norm": 0.49216288328170776,
      "learning_rate": 0.00019987151708338215,
      "loss": 3.7335,
      "step": 620
    },
    {
      "epoch": 0.016657701584216828,
      "grad_norm": 0.48704585433006287,
      "learning_rate": 0.00019986309608824567,
      "loss": 3.709,
      "step": 640
    },
    {
      "epoch": 0.017178254758723605,
      "grad_norm": 0.5498775243759155,
      "learning_rate": 0.00019985440800783405,
      "loss": 3.695,
      "step": 660
    },
    {
      "epoch": 0.01769880793323038,
      "grad_norm": 0.5087308287620544,
      "learning_rate": 0.0001998454528653836,
      "loss": 3.6842,
      "step": 680
    },
    {
      "epoch": 0.018219361107737156,
      "grad_norm": 0.4684169292449951,
      "learning_rate": 0.00019983623068484506,
      "loss": 3.7128,
      "step": 700
    },
    {
      "epoch": 0.01873991428224393,
      "grad_norm": 0.504634439945221,
      "learning_rate": 0.00019982674149088321,
      "loss": 3.6875,
      "step": 720
    },
    {
      "epoch": 0.019260467456750707,
      "grad_norm": 0.811528205871582,
      "learning_rate": 0.00019981698530887704,
      "loss": 3.6821,
      "step": 740
    },
    {
      "epoch": 0.019781020631257484,
      "grad_norm": 0.4771095812320709,
      "learning_rate": 0.00019980696216491964,
      "loss": 3.6776,
      "step": 760
    },
    {
      "epoch": 0.020301573805764257,
      "grad_norm": 0.4765424132347107,
      "learning_rate": 0.00019979667208581804,
      "loss": 3.6727,
      "step": 780
    },
    {
      "epoch": 0.020822126980271034,
      "grad_norm": 0.5483406782150269,
      "learning_rate": 0.0001997861150990932,
      "loss": 3.6504,
      "step": 800
    },
    {
      "epoch": 0.02134268015477781,
      "grad_norm": 0.7404278516769409,
      "learning_rate": 0.00019977529123297992,
      "loss": 3.6567,
      "step": 820
    },
    {
      "epoch": 0.021863233329284585,
      "grad_norm": 0.5085668563842773,
      "learning_rate": 0.0001997642005164268,
      "loss": 3.6285,
      "step": 840
    },
    {
      "epoch": 0.022383786503791362,
      "grad_norm": 0.44109195470809937,
      "learning_rate": 0.00019975284297909612,
      "loss": 3.647,
      "step": 860
    },
    {
      "epoch": 0.02290433967829814,
      "grad_norm": 0.4293036162853241,
      "learning_rate": 0.00019974121865136372,
      "loss": 3.6617,
      "step": 880
    },
    {
      "epoch": 0.023424892852804913,
      "grad_norm": 0.5700727701187134,
      "learning_rate": 0.0001997293275643191,
      "loss": 3.6165,
      "step": 900
    },
    {
      "epoch": 0.02394544602731169,
      "grad_norm": 0.5796371102333069,
      "learning_rate": 0.00019971716974976513,
      "loss": 3.6726,
      "step": 920
    },
    {
      "epoch": 0.024465999201818467,
      "grad_norm": 0.4691178500652313,
      "learning_rate": 0.00019970474524021804,
      "loss": 3.6796,
      "step": 940
    },
    {
      "epoch": 0.02498655237632524,
      "grad_norm": 0.5757220983505249,
      "learning_rate": 0.00019969205406890738,
      "loss": 3.6233,
      "step": 960
    },
    {
      "epoch": 0.025507105550832018,
      "grad_norm": 0.6654652953147888,
      "learning_rate": 0.00019967909626977584,
      "loss": 3.6389,
      "step": 980
    },
    {
      "epoch": 0.026027658725338795,
      "grad_norm": 0.5949297547340393,
      "learning_rate": 0.00019966587187747925,
      "loss": 3.6308,
      "step": 1000
    },
    {
      "epoch": 0.026548211899845568,
      "grad_norm": 0.5524229407310486,
      "learning_rate": 0.00019965238092738643,
      "loss": 3.662,
      "step": 1020
    },
    {
      "epoch": 0.027068765074352345,
      "grad_norm": 0.5579757690429688,
      "learning_rate": 0.00019963862345557916,
      "loss": 3.654,
      "step": 1040
    },
    {
      "epoch": 0.027589318248859122,
      "grad_norm": 0.5119760632514954,
      "learning_rate": 0.00019962459949885193,
      "loss": 3.6056,
      "step": 1060
    },
    {
      "epoch": 0.028109871423365896,
      "grad_norm": 0.440817654132843,
      "learning_rate": 0.00019961030909471206,
      "loss": 3.6525,
      "step": 1080
    },
    {
      "epoch": 0.028630424597872673,
      "grad_norm": 0.45368555188179016,
      "learning_rate": 0.00019959575228137945,
      "loss": 3.612,
      "step": 1100
    },
    {
      "epoch": 0.02915097777237945,
      "grad_norm": 0.5261623859405518,
      "learning_rate": 0.0001995809290977864,
      "loss": 3.5947,
      "step": 1120
    },
    {
      "epoch": 0.029671530946886224,
      "grad_norm": 0.5620899200439453,
      "learning_rate": 0.00019956583958357786,
      "loss": 3.6189,
      "step": 1140
    },
    {
      "epoch": 0.030192084121393,
      "grad_norm": 0.5233215093612671,
      "learning_rate": 0.0001995504837791109,
      "loss": 3.6356,
      "step": 1160
    },
    {
      "epoch": 0.030712637295899778,
      "grad_norm": 0.5295366644859314,
      "learning_rate": 0.00019953486172545485,
      "loss": 3.6193,
      "step": 1180
    },
    {
      "epoch": 0.03123319047040655,
      "grad_norm": 0.6000590324401855,
      "learning_rate": 0.00019951897346439106,
      "loss": 3.6021,
      "step": 1200
    },
    {
      "epoch": 0.031753743644913325,
      "grad_norm": 0.5048771500587463,
      "learning_rate": 0.00019950281903841294,
      "loss": 3.6064,
      "step": 1220
    },
    {
      "epoch": 0.0322742968194201,
      "grad_norm": 0.5192753076553345,
      "learning_rate": 0.00019948639849072576,
      "loss": 3.628,
      "step": 1240
    },
    {
      "epoch": 0.03279484999392688,
      "grad_norm": 0.5019574761390686,
      "learning_rate": 0.00019946971186524652,
      "loss": 3.6385,
      "step": 1260
    },
    {
      "epoch": 0.033315403168433656,
      "grad_norm": 0.5954020619392395,
      "learning_rate": 0.00019945275920660378,
      "loss": 3.6272,
      "step": 1280
    },
    {
      "epoch": 0.03383595634294043,
      "grad_norm": 0.4911520779132843,
      "learning_rate": 0.00019943554056013773,
      "loss": 3.5759,
      "step": 1300
    },
    {
      "epoch": 0.03435650951744721,
      "grad_norm": 0.500883936882019,
      "learning_rate": 0.00019941805597189978,
      "loss": 3.5883,
      "step": 1320
    },
    {
      "epoch": 0.03487706269195398,
      "grad_norm": 0.7456203103065491,
      "learning_rate": 0.00019940030548865284,
      "loss": 3.5915,
      "step": 1340
    },
    {
      "epoch": 0.03539761586646076,
      "grad_norm": 0.8401622772216797,
      "learning_rate": 0.0001993822891578708,
      "loss": 3.5949,
      "step": 1360
    },
    {
      "epoch": 0.035918169040967535,
      "grad_norm": 0.5454252362251282,
      "learning_rate": 0.00019936400702773855,
      "loss": 3.6008,
      "step": 1380
    },
    {
      "epoch": 0.03643872221547431,
      "grad_norm": 0.8064963221549988,
      "learning_rate": 0.00019934545914715188,
      "loss": 3.6322,
      "step": 1400
    },
    {
      "epoch": 0.03695927538998109,
      "grad_norm": 0.5449928045272827,
      "learning_rate": 0.00019932664556571744,
      "loss": 3.5753,
      "step": 1420
    },
    {
      "epoch": 0.03747982856448786,
      "grad_norm": 0.49472466111183167,
      "learning_rate": 0.00019930756633375238,
      "loss": 3.6083,
      "step": 1440
    },
    {
      "epoch": 0.038000381738994636,
      "grad_norm": 0.4645421504974365,
      "learning_rate": 0.00019928822150228442,
      "loss": 3.5998,
      "step": 1460
    },
    {
      "epoch": 0.03852093491350141,
      "grad_norm": 0.49327659606933594,
      "learning_rate": 0.0001992686111230515,
      "loss": 3.5528,
      "step": 1480
    },
    {
      "epoch": 0.03904148808800819,
      "grad_norm": 0.5574433207511902,
      "learning_rate": 0.00019924873524850196,
      "loss": 3.591,
      "step": 1500
    },
    {
      "epoch": 0.03956204126251497,
      "grad_norm": 0.5722444653511047,
      "learning_rate": 0.00019922859393179404,
      "loss": 3.5801,
      "step": 1520
    },
    {
      "epoch": 0.040082594437021744,
      "grad_norm": 0.48366034030914307,
      "learning_rate": 0.000199208187226796,
      "loss": 3.5703,
      "step": 1540
    },
    {
      "epoch": 0.040603147611528514,
      "grad_norm": 0.6313353776931763,
      "learning_rate": 0.0001991875151880859,
      "loss": 3.5747,
      "step": 1560
    },
    {
      "epoch": 0.04112370078603529,
      "grad_norm": 0.5576560497283936,
      "learning_rate": 0.00019916657787095134,
      "loss": 3.5976,
      "step": 1580
    },
    {
      "epoch": 0.04164425396054207,
      "grad_norm": 0.5665624737739563,
      "learning_rate": 0.0001991453753313895,
      "loss": 3.5684,
      "step": 1600
    },
    {
      "epoch": 0.042164807135048846,
      "grad_norm": 0.5328001976013184,
      "learning_rate": 0.0001991239076261069,
      "loss": 3.587,
      "step": 1620
    },
    {
      "epoch": 0.04268536030955562,
      "grad_norm": 0.4984259605407715,
      "learning_rate": 0.0001991021748125192,
      "loss": 3.5457,
      "step": 1640
    },
    {
      "epoch": 0.0432059134840624,
      "grad_norm": 0.5838313102722168,
      "learning_rate": 0.0001990801769487511,
      "loss": 3.5792,
      "step": 1660
    },
    {
      "epoch": 0.04372646665856917,
      "grad_norm": 0.4797563850879669,
      "learning_rate": 0.00019905791409363622,
      "loss": 3.5574,
      "step": 1680
    },
    {
      "epoch": 0.04424701983307595,
      "grad_norm": 0.5086127519607544,
      "learning_rate": 0.0001990353863067169,
      "loss": 3.5611,
      "step": 1700
    },
    {
      "epoch": 0.044767573007582724,
      "grad_norm": 0.502778947353363,
      "learning_rate": 0.00019901259364824402,
      "loss": 3.5967,
      "step": 1720
    },
    {
      "epoch": 0.0452881261820895,
      "grad_norm": 0.5233121514320374,
      "learning_rate": 0.00019898953617917685,
      "loss": 3.5919,
      "step": 1740
    },
    {
      "epoch": 0.04580867935659628,
      "grad_norm": 0.5472354292869568,
      "learning_rate": 0.00019896621396118288,
      "loss": 3.5598,
      "step": 1760
    },
    {
      "epoch": 0.046329232531103055,
      "grad_norm": 0.5228177309036255,
      "learning_rate": 0.00019894262705663784,
      "loss": 3.5311,
      "step": 1780
    },
    {
      "epoch": 0.046849785705609825,
      "grad_norm": 0.5137920379638672,
      "learning_rate": 0.00019891877552862517,
      "loss": 3.579,
      "step": 1800
    },
    {
      "epoch": 0.0473703388801166,
      "grad_norm": 0.4788419306278229,
      "learning_rate": 0.00019889465944093607,
      "loss": 3.5573,
      "step": 1820
    },
    {
      "epoch": 0.04789089205462338,
      "grad_norm": 0.4873778522014618,
      "learning_rate": 0.00019887027885806945,
      "loss": 3.4941,
      "step": 1840
    },
    {
      "epoch": 0.04841144522913016,
      "grad_norm": 0.5099794864654541,
      "learning_rate": 0.0001988456338452315,
      "loss": 3.5368,
      "step": 1860
    },
    {
      "epoch": 0.048931998403636934,
      "grad_norm": 0.5024635791778564,
      "learning_rate": 0.00019882072446833563,
      "loss": 3.5131,
      "step": 1880
    },
    {
      "epoch": 0.04945255157814371,
      "grad_norm": 0.5285683870315552,
      "learning_rate": 0.00019879555079400235,
      "loss": 3.522,
      "step": 1900
    },
    {
      "epoch": 0.04997310475265048,
      "grad_norm": 0.886477530002594,
      "learning_rate": 0.00019877011288955897,
      "loss": 3.5397,
      "step": 1920
    },
    {
      "epoch": 0.05049365792715726,
      "grad_norm": 0.7505388855934143,
      "learning_rate": 0.00019874441082303962,
      "loss": 3.5569,
      "step": 1940
    },
    {
      "epoch": 0.051014211101664035,
      "grad_norm": 0.487406849861145,
      "learning_rate": 0.00019871844466318474,
      "loss": 3.5227,
      "step": 1960
    },
    {
      "epoch": 0.05153476427617081,
      "grad_norm": 0.5987463593482971,
      "learning_rate": 0.00019869221447944125,
      "loss": 3.5498,
      "step": 1980
    },
    {
      "epoch": 0.05205531745067759,
      "grad_norm": 0.584394097328186,
      "learning_rate": 0.00019866572034196213,
      "loss": 3.5415,
      "step": 2000
    },
    {
      "epoch": 0.05257587062518436,
      "grad_norm": 0.6229021549224854,
      "learning_rate": 0.00019863896232160636,
      "loss": 3.5288,
      "step": 2020
    },
    {
      "epoch": 0.053096423799691136,
      "grad_norm": 0.5300812125205994,
      "learning_rate": 0.00019861194048993863,
      "loss": 3.5194,
      "step": 2040
    },
    {
      "epoch": 0.053616976974197914,
      "grad_norm": 0.5499328970909119,
      "learning_rate": 0.0001985846549192292,
      "loss": 3.5688,
      "step": 2060
    },
    {
      "epoch": 0.05413753014870469,
      "grad_norm": 0.5752665400505066,
      "learning_rate": 0.00019855710568245373,
      "loss": 3.5153,
      "step": 2080
    },
    {
      "epoch": 0.05465808332321147,
      "grad_norm": 0.4599245488643646,
      "learning_rate": 0.00019852929285329304,
      "loss": 3.5686,
      "step": 2100
    },
    {
      "epoch": 0.055178636497718245,
      "grad_norm": 0.638130784034729,
      "learning_rate": 0.00019850121650613294,
      "loss": 3.5204,
      "step": 2120
    },
    {
      "epoch": 0.055699189672225015,
      "grad_norm": 0.5395076274871826,
      "learning_rate": 0.00019847287671606405,
      "loss": 3.5156,
      "step": 2140
    },
    {
      "epoch": 0.05621974284673179,
      "grad_norm": 0.5301132202148438,
      "learning_rate": 0.00019844427355888148,
      "loss": 3.5446,
      "step": 2160
    },
    {
      "epoch": 0.05674029602123857,
      "grad_norm": 0.5646910667419434,
      "learning_rate": 0.00019841540711108485,
      "loss": 3.531,
      "step": 2180
    },
    {
      "epoch": 0.057260849195745346,
      "grad_norm": 0.6725537776947021,
      "learning_rate": 0.00019838627744987785,
      "loss": 3.5278,
      "step": 2200
    },
    {
      "epoch": 0.05778140237025212,
      "grad_norm": 0.5010442137718201,
      "learning_rate": 0.00019835688465316817,
      "loss": 3.5737,
      "step": 2220
    },
    {
      "epoch": 0.0583019555447589,
      "grad_norm": 0.5495448112487793,
      "learning_rate": 0.00019832722879956728,
      "loss": 3.5181,
      "step": 2240
    },
    {
      "epoch": 0.05882250871926567,
      "grad_norm": 0.5481933355331421,
      "learning_rate": 0.0001982973099683902,
      "loss": 3.5529,
      "step": 2260
    },
    {
      "epoch": 0.05934306189377245,
      "grad_norm": 0.5865151882171631,
      "learning_rate": 0.00019826712823965524,
      "loss": 3.4962,
      "step": 2280
    },
    {
      "epoch": 0.059863615068279225,
      "grad_norm": 0.5511869192123413,
      "learning_rate": 0.00019823668369408384,
      "loss": 3.5233,
      "step": 2300
    },
    {
      "epoch": 0.060384168242786,
      "grad_norm": 0.5174809098243713,
      "learning_rate": 0.00019820597641310043,
      "loss": 3.5218,
      "step": 2320
    },
    {
      "epoch": 0.06090472141729278,
      "grad_norm": 0.6208744645118713,
      "learning_rate": 0.00019817500647883204,
      "loss": 3.5371,
      "step": 2340
    },
    {
      "epoch": 0.061425274591799556,
      "grad_norm": 0.5282926559448242,
      "learning_rate": 0.0001981437739741082,
      "loss": 3.5267,
      "step": 2360
    },
    {
      "epoch": 0.061945827766306326,
      "grad_norm": 0.5010799765586853,
      "learning_rate": 0.0001981122789824607,
      "loss": 3.5011,
      "step": 2380
    },
    {
      "epoch": 0.0624663809408131,
      "grad_norm": 0.5648534893989563,
      "learning_rate": 0.00019808052158812336,
      "loss": 3.5281,
      "step": 2400
    },
    {
      "epoch": 0.06298693411531987,
      "grad_norm": 0.7556483745574951,
      "learning_rate": 0.00019804850187603177,
      "loss": 3.5564,
      "step": 2420
    },
    {
      "epoch": 0.06350748728982665,
      "grad_norm": 0.508564293384552,
      "learning_rate": 0.00019801621993182307,
      "loss": 3.5381,
      "step": 2440
    },
    {
      "epoch": 0.06402804046433343,
      "grad_norm": 0.5181660652160645,
      "learning_rate": 0.00019798367584183583,
      "loss": 3.5419,
      "step": 2460
    },
    {
      "epoch": 0.0645485936388402,
      "grad_norm": 0.5391380786895752,
      "learning_rate": 0.00019795086969310964,
      "loss": 3.5259,
      "step": 2480
    },
    {
      "epoch": 0.06506914681334698,
      "grad_norm": 0.4523926377296448,
      "learning_rate": 0.0001979178015733851,
      "loss": 3.5281,
      "step": 2500
    },
    {
      "epoch": 0.06558969998785376,
      "grad_norm": 0.5444406270980835,
      "learning_rate": 0.00019788447157110324,
      "loss": 3.5316,
      "step": 2520
    },
    {
      "epoch": 0.06611025316236054,
      "grad_norm": 0.5530903935432434,
      "learning_rate": 0.00019785087977540572,
      "loss": 3.4947,
      "step": 2540
    },
    {
      "epoch": 0.06663080633686731,
      "grad_norm": 0.5229605436325073,
      "learning_rate": 0.00019781702627613424,
      "loss": 3.5108,
      "step": 2560
    },
    {
      "epoch": 0.06715135951137409,
      "grad_norm": 0.5143314599990845,
      "learning_rate": 0.0001977829111638305,
      "loss": 3.4677,
      "step": 2580
    },
    {
      "epoch": 0.06767191268588087,
      "grad_norm": 0.5345378518104553,
      "learning_rate": 0.0001977485345297358,
      "loss": 3.5071,
      "step": 2600
    },
    {
      "epoch": 0.06819246586038764,
      "grad_norm": 0.5212274193763733,
      "learning_rate": 0.000197713896465791,
      "loss": 3.516,
      "step": 2620
    },
    {
      "epoch": 0.06871301903489442,
      "grad_norm": 0.4808492958545685,
      "learning_rate": 0.00019767899706463603,
      "loss": 3.5499,
      "step": 2640
    },
    {
      "epoch": 0.06923357220940118,
      "grad_norm": 0.5475588440895081,
      "learning_rate": 0.0001976438364196099,
      "loss": 3.5673,
      "step": 2660
    },
    {
      "epoch": 0.06975412538390796,
      "grad_norm": 0.4662018120288849,
      "learning_rate": 0.00019760841462475025,
      "loss": 3.5004,
      "step": 2680
    },
    {
      "epoch": 0.07027467855841474,
      "grad_norm": 0.6194716095924377,
      "learning_rate": 0.0001975727317747931,
      "loss": 3.5413,
      "step": 2700
    },
    {
      "epoch": 0.07079523173292152,
      "grad_norm": 0.5391833782196045,
      "learning_rate": 0.00019753678796517282,
      "loss": 3.55,
      "step": 2720
    },
    {
      "epoch": 0.07131578490742829,
      "grad_norm": 0.5219372510910034,
      "learning_rate": 0.00019750058329202162,
      "loss": 3.4783,
      "step": 2740
    },
    {
      "epoch": 0.07183633808193507,
      "grad_norm": 0.4674382209777832,
      "learning_rate": 0.0001974641178521694,
      "loss": 3.4737,
      "step": 2760
    },
    {
      "epoch": 0.07235689125644185,
      "grad_norm": 0.46463659405708313,
      "learning_rate": 0.0001974273917431435,
      "loss": 3.503,
      "step": 2780
    },
    {
      "epoch": 0.07287744443094862,
      "grad_norm": 0.4742620587348938,
      "learning_rate": 0.00019739040506316845,
      "loss": 3.4957,
      "step": 2800
    },
    {
      "epoch": 0.0733979976054554,
      "grad_norm": 0.8183860778808594,
      "learning_rate": 0.00019735315791116564,
      "loss": 3.5029,
      "step": 2820
    },
    {
      "epoch": 0.07391855077996218,
      "grad_norm": 0.5792810916900635,
      "learning_rate": 0.00019731565038675312,
      "loss": 3.4998,
      "step": 2840
    },
    {
      "epoch": 0.07443910395446895,
      "grad_norm": 0.61552894115448,
      "learning_rate": 0.00019727788259024526,
      "loss": 3.4698,
      "step": 2860
    },
    {
      "epoch": 0.07495965712897572,
      "grad_norm": 0.5296409130096436,
      "learning_rate": 0.0001972398546226526,
      "loss": 3.4985,
      "step": 2880
    },
    {
      "epoch": 0.0754802103034825,
      "grad_norm": 0.5124635696411133,
      "learning_rate": 0.0001972015665856815,
      "loss": 3.5068,
      "step": 2900
    },
    {
      "epoch": 0.07600076347798927,
      "grad_norm": 0.547118067741394,
      "learning_rate": 0.00019716301858173382,
      "loss": 3.5046,
      "step": 2920
    },
    {
      "epoch": 0.07652131665249605,
      "grad_norm": 0.5683484077453613,
      "learning_rate": 0.00019712421071390674,
      "loss": 3.5279,
      "step": 2940
    },
    {
      "epoch": 0.07704186982700283,
      "grad_norm": 0.778019368648529,
      "learning_rate": 0.00019708514308599252,
      "loss": 3.4864,
      "step": 2960
    },
    {
      "epoch": 0.0775624230015096,
      "grad_norm": 0.5860201716423035,
      "learning_rate": 0.00019704581580247803,
      "loss": 3.4879,
      "step": 2980
    },
    {
      "epoch": 0.07808297617601638,
      "grad_norm": 0.5510878562927246,
      "learning_rate": 0.00019700622896854468,
      "loss": 3.5175,
      "step": 3000
    },
    {
      "epoch": 0.07860352935052316,
      "grad_norm": 0.48584944009780884,
      "learning_rate": 0.00019696638269006803,
      "loss": 3.5112,
      "step": 3020
    },
    {
      "epoch": 0.07912408252502993,
      "grad_norm": 0.5269086956977844,
      "learning_rate": 0.00019692627707361746,
      "loss": 3.4794,
      "step": 3040
    },
    {
      "epoch": 0.07964463569953671,
      "grad_norm": 0.5633729696273804,
      "learning_rate": 0.00019688591222645607,
      "loss": 3.5115,
      "step": 3060
    },
    {
      "epoch": 0.08016518887404349,
      "grad_norm": 0.5569837093353271,
      "learning_rate": 0.00019684528825654024,
      "loss": 3.4923,
      "step": 3080
    },
    {
      "epoch": 0.08068574204855027,
      "grad_norm": 0.5002463459968567,
      "learning_rate": 0.00019680440527251926,
      "loss": 3.4773,
      "step": 3100
    },
    {
      "epoch": 0.08120629522305703,
      "grad_norm": 0.4975096881389618,
      "learning_rate": 0.0001967632633837354,
      "loss": 3.4981,
      "step": 3120
    },
    {
      "epoch": 0.0817268483975638,
      "grad_norm": 0.481128454208374,
      "learning_rate": 0.00019672186270022307,
      "loss": 3.5044,
      "step": 3140
    },
    {
      "epoch": 0.08224740157207058,
      "grad_norm": 0.6880462169647217,
      "learning_rate": 0.0001966802033327091,
      "loss": 3.4883,
      "step": 3160
    },
    {
      "epoch": 0.08276795474657736,
      "grad_norm": 0.5052451491355896,
      "learning_rate": 0.000196638285392612,
      "loss": 3.4851,
      "step": 3180
    },
    {
      "epoch": 0.08328850792108414,
      "grad_norm": 0.5671523809432983,
      "learning_rate": 0.00019659610899204198,
      "loss": 3.4573,
      "step": 3200
    },
    {
      "epoch": 0.08380906109559091,
      "grad_norm": 0.5347433686256409,
      "learning_rate": 0.0001965536742438003,
      "loss": 3.5039,
      "step": 3220
    },
    {
      "epoch": 0.08432961427009769,
      "grad_norm": 0.5257036089897156,
      "learning_rate": 0.00019651098126137942,
      "loss": 3.4855,
      "step": 3240
    },
    {
      "epoch": 0.08485016744460447,
      "grad_norm": 0.5895543694496155,
      "learning_rate": 0.00019646803015896226,
      "loss": 3.4838,
      "step": 3260
    },
    {
      "epoch": 0.08537072061911125,
      "grad_norm": 0.5273109078407288,
      "learning_rate": 0.0001964248210514222,
      "loss": 3.4879,
      "step": 3280
    },
    {
      "epoch": 0.08589127379361802,
      "grad_norm": 0.565952718257904,
      "learning_rate": 0.00019638135405432256,
      "loss": 3.4985,
      "step": 3300
    },
    {
      "epoch": 0.0864118269681248,
      "grad_norm": 0.5014436841011047,
      "learning_rate": 0.00019633762928391647,
      "loss": 3.4837,
      "step": 3320
    },
    {
      "epoch": 0.08693238014263156,
      "grad_norm": 0.4900112450122833,
      "learning_rate": 0.0001962936468571465,
      "loss": 3.4499,
      "step": 3340
    },
    {
      "epoch": 0.08745293331713834,
      "grad_norm": 0.48782122135162354,
      "learning_rate": 0.00019624940689164422,
      "loss": 3.4737,
      "step": 3360
    },
    {
      "epoch": 0.08797348649164512,
      "grad_norm": 0.5506260991096497,
      "learning_rate": 0.00019620490950573007,
      "loss": 3.4982,
      "step": 3380
    },
    {
      "epoch": 0.0884940396661519,
      "grad_norm": 0.5621121525764465,
      "learning_rate": 0.0001961601548184129,
      "loss": 3.4804,
      "step": 3400
    },
    {
      "epoch": 0.08901459284065867,
      "grad_norm": 0.5001835227012634,
      "learning_rate": 0.00019611514294938984,
      "loss": 3.4772,
      "step": 3420
    },
    {
      "epoch": 0.08953514601516545,
      "grad_norm": 0.7326066493988037,
      "learning_rate": 0.00019606987401904572,
      "loss": 3.5016,
      "step": 3440
    },
    {
      "epoch": 0.09005569918967223,
      "grad_norm": 0.5249329209327698,
      "learning_rate": 0.00019602434814845293,
      "loss": 3.5005,
      "step": 3460
    },
    {
      "epoch": 0.090576252364179,
      "grad_norm": 0.5368496179580688,
      "learning_rate": 0.0001959785654593711,
      "loss": 3.5167,
      "step": 3480
    },
    {
      "epoch": 0.09109680553868578,
      "grad_norm": 0.5588676333427429,
      "learning_rate": 0.0001959325260742467,
      "loss": 3.4649,
      "step": 3500
    },
    {
      "epoch": 0.09161735871319256,
      "grad_norm": 0.49879249930381775,
      "learning_rate": 0.00019588623011621267,
      "loss": 3.5034,
      "step": 3520
    },
    {
      "epoch": 0.09213791188769933,
      "grad_norm": 0.5207927823066711,
      "learning_rate": 0.0001958396777090882,
      "loss": 3.4517,
      "step": 3540
    },
    {
      "epoch": 0.09265846506220611,
      "grad_norm": 0.587238609790802,
      "learning_rate": 0.00019579286897737844,
      "loss": 3.4949,
      "step": 3560
    },
    {
      "epoch": 0.09317901823671287,
      "grad_norm": 0.5273112654685974,
      "learning_rate": 0.00019574580404627394,
      "loss": 3.4366,
      "step": 3580
    },
    {
      "epoch": 0.09369957141121965,
      "grad_norm": 0.5513274669647217,
      "learning_rate": 0.0001956984830416506,
      "loss": 3.4694,
      "step": 3600
    }
  ],
  "logging_steps": 20,
  "max_steps": 38420,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.2430090092544e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
